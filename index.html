<!--
<!DOCTYPE html>
<html data-bs-theme="light" lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no">
    <title>v2r</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css">
    <link rel="stylesheet" href="/assets/css/Brygada%201918.css">
    <link rel="stylesheet" href="/assets/css/Roboto.css">
    <link rel="stylesheet" href="/assets/css/Articles-Badges-images.css">
</head>

<body>
    <div class="container py-4 py-xl-5" style="height: 384px;">
        <div class="row mb-5">
            <div class="col-md-8 col-xl-6 col-xxl-11 offset-xxl-3 text-center mx-auto" style="height: 300px;">
                <h2 style="text-align:center;font-weight:bold;color:var(--bs-emphasis-color);font-size:40px;height:173px;"><br><span style="color:rgb(31, 35, 40);">Video2Reward: Generating Reward Function from Videos for Legged Robot Behavior Learning</span></h2>
                <p class="w-lg-50" style="font-size: 22px;transform: perspective(0px) translate(0px) scale(0.96);width: 1186px;height: 61px;color: var(--bs-emphasis-color);">Runhao Zeng, Dingjie Zhou, Qiwei Liang, Junlin Liu, Hui Li, Changxin Huang, Jianqiang Li,<br>Xiping Hu and Fuchun Sun</p><iframe allowfullscreen="" frameborder="0" width="560" height="315"></iframe>
            </div>
        </div>    
    </div>
    <div class="container is-max-desktop">        
        <div class="columns is-centered has-text-centered">
            <video poster="" id="" autoplay controls muted loop width="100%" playbackRate=2.0 style="border-radius: 5px;">
                <source src="assets/Demo_video.mp4" type="video/mp4">
            </video>
        </div>
    </div>
    <div class="container py-4 py-xl-5">
        <div class="row mb-5" style="height: 1000px;">
            <div class="col-md-8 col-xl-6 col-xxl-9 text-center mx-auto" style="height: 800px;">
                <h2><strong><span style="color: rgb(54, 54, 54);">Abstract</span></strong></h2>
                <p class="w-lg-50" style="text-align: justify;font-size: 22px;font-family: Roboto, sans-serif;"><br><span style="color: rgb(31, 35, 40);">Learning behavior in legged robots presents a significant challenge due to its inherent instability and complex constraints. Recent research has proposed the use of a large language model (LLM) to generate reward functions in reinforcement learning, thereby replacing the need for manually designed rewards by experts. However, this approach, which relies on textual descriptions to define learning objectives, fails to achieve controllable and precise behavior learning with clear directionality. In this paper, we introduce a new video2reward method, which directly generates reward functions from videos depicting the behaviors to be mimicked and learned. Specifically, we first process videos containing the target behaviors, converting the motion information of individuals in the videos into keypoint trajectories represented as coordinates through a video2text transforming module. These trajectories are then fed into an LLM to generate the reward function, which in turn is used to train the policy. To enhance the quality of the reward function, we develop a video-assisted iterative reward refinement scheme that visually assesses the learned behaviors and provides textual feedback to the LLM. This feedback guides the LLM to continually refine the reward function, ultimately facilitating more efficient behavior learning. Experimental results on tasks involving bipedal and quadrupedal robot motion control demonstrate that our method surpasses the performance of state-of-the-art LLM-based reward generation methods by over 37.6% in terms of human normalized score. More importantly, by switching video inputs, we find our method can rapidly learn diverse motion behaviors such as walking and running.</span><br><br></p>
            </div>
        </div>
    </div>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js"></script>
</body>

</html>
-->
<!DOCTYPE html>
<html data-bs-theme="light" lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no">
    <title>v2r</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css">
    <link rel="stylesheet" href="/assets/css/Brygada%201918.css">
    <link rel="stylesheet" href="/assets/css/Roboto.css">
    <link rel="stylesheet" href="/assets/css/Articles-Badges-images.css">
</head>

<body>
    <div class="container py-4 py-xl-5" style="height: auto;">
        <div class="row mb-5">
            <div class="col-md-8 col-xl-6 col-xxl-11 offset-xxl-3 text-center mx-auto" style="height: auto;">
                <h2 style="text-align:center;font-weight:bold;color:var(--bs-emphasis-color);font-size:40px;height:auto;">
                    Video2Reward: Generating Reward Function from Videos for Legged Robot Behavior Learning
                </h2>
                <p class="w-lg-50" style="font-size: 22px;transform: perspective(0px) translate(0px) scale(0.96);width: 100%;height:auto;color: var(--bs-emphasis-color);">
                    Runhao Zeng, Dingjie Zhou, Qiwei Liang, Junlin Liu, Hui Li, Changxin Huang, Jianqiang Li,<br>Xiping Hu and Fuchun Sun
                </p>
            </div>
        </div>
        <div class="row">
            <div class="col-12 text-center">
                <video poster="" id="" autoplay controls muted loop width="80%" style="border-radius: 5px; margin-top: 20px;">
                    <source src="assets/Demo_video.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
            </div>
        </div>
    </div>

    <div class="container py-4 py-xl-5">
        <div class="row mb-5">
            <div class="col-md-8 col-xl-6 col-xxl-9 text-center mx-auto">
                <h2><strong><span style="color: rgb(54, 54, 54);">Abstract</span></strong></h2>
                <p class="w-lg-50" style="text-align: justify;font-size: 22px;font-family: Roboto, sans-serif;">
                    Learning behavior in legged robots presents a significant challenge due to its inherent instability and complex constraints. Recent research has proposed the use of a large language model (LLM) to generate reward functions in reinforcement learning, thereby replacing the need for manually designed rewards by experts. However, this approach, which relies on textual descriptions to define learning objectives, fails to achieve controllable and precise behavior learning with clear directionality. In this paper, we introduce a new video2reward method, which directly generates reward functions from videos depicting the behaviors to be mimicked and learned. Specifically, we first process videos containing the target behaviors, converting the motion information of individuals in the videos into keypoint trajectories represented as coordinates through a video2text transforming module. These trajectories are then fed into an LLM to generate the reward function, which in turn is used to train the policy. To enhance the quality of the reward function, we develop a video-assisted iterative reward refinement scheme that visually assesses the learned behaviors and provides textual feedback to the LLM. This feedback guides the LLM to continually refine the reward function, ultimately facilitating more efficient behavior learning. Experimental results on tasks involving bipedal and quadrupedal robot motion control demonstrate that our method surpasses the performance of state-of-the-art LLM-based reward generation methods by over 37.6% in terms of human normalized score. More importantly, by switching video inputs, we find our method can rapidly learn diverse motion behaviors such as walking and running.
                </p>
            </div>
        </div>
    </div>
    
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js"></script>
</body>

</html>
